{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "def build_model(data):\n",
    "\n",
    "    print(data.shape)\n",
    "    # this is the size of our encoded representations\n",
    "    encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "    # this is our input placeholder\n",
    "    original_dim=data.shape[1]\n",
    "    input_img = Input(shape=(original_dim,))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "\n",
    "    encoded = Dense(256, activation='tanh',\n",
    "                    activity_regularizer=regularizers.l1(2*10e-5))(input_img)\n",
    "    encoded = Dense(128, activation='tanh',\n",
    "                    activity_regularizer=regularizers.l1(2*10e-5))(encoded)\n",
    "    encoded = Dense(32, activation='tanh',\n",
    "                    activity_regularizer=regularizers.l1(2*10e-5))(encoded)\n",
    "\n",
    "    decoded = Dense(128, activation='tanh')(encoded)\n",
    "    decoded = Dense(256, activation='tanh')(decoded)\n",
    "    decoded = Dense(original_dim, activation='tanh')(decoded)\n",
    "\n",
    "    # this model maps an input to its reconstruction\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "\n",
    "    # this model maps an input to its encoded representation\n",
    "    encoder = Model(input_img, encoded)\n",
    "    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "\n",
    "    autoencoder.fit(data, data,\n",
    "                    epochs=10,\n",
    "                    batch_size=100,\n",
    "                    shuffle=True)\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decomposition import CanICA\n",
    "def prepare_data(func_filenames):\n",
    "    canica = CanICA(memory=\"nilearn_cache\", memory_level=2,\n",
    "                    threshold=3., verbose=10, random_state=0, \n",
    "                    mask='/home/share/TmpData/Qinglin/ADHD200_Athena_preproc_flirtfix/ADHD200_mask_152_4mm.nii.gz')\n",
    "    data=canica.prepare_data(func_filenames)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "def corr(all_time_series):\n",
    "    connectivity_biomarkers = {}\n",
    "    conn_measure = ConnectivityMeasure(kind='correlation', vectorize=True)\n",
    "    connectivity_biomarkers = conn_measure.fit_transform(all_time_series)\n",
    "    return connectivity_biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def classify(train_X,train_Y, test_X, test_Y):\n",
    "    names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "             \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "             \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(3),\n",
    "        SVC(kernel=\"linear\", C=0.025),\n",
    "        SVC(gamma=2, C=1),\n",
    "        GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "        DecisionTreeClassifier(max_depth=5),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "        MLPClassifier(alpha=1),\n",
    "        AdaBoostClassifier(),\n",
    "        GaussianNB(),\n",
    "        QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(train_X, train_Y) \n",
    "        score=clf.score(test_X,test_Y)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading\n"
     ]
    }
   ],
   "source": [
    "#X=np.load('/home/share/TmpData/Qinglin/ADHD200_Athena_preproc_flirtfix/NYU/All_Data_20.npy')\n",
    "print(\"loading\")\n",
    "X=np.load('/home/share/TmpData/Qinglin/ADHD200_Athena_preproc_flirtfix/NYU/All_Data.npy')\n",
    "Y=np.load('/home/share/TmpData/Qinglin/ADHD200_Athena_preproc_flirtfix/NYU/All_Labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=172"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11  21  25  31  32  34  35  36  41  42  50  52  55  63  70  75  85  90\n",
      " 100 107 109 116 120 125 132 135 139 141 147 148 151 159 166 169 172 184\n",
      " 189 191 194 197 208 210 211 215]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "    \n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "# trick. split(Y,Y) instead of split(X,Y) due to X is already concatnated \n",
    "for train,test in kfold.split(Y,Y):   \n",
    "    #indexing of specific subjects\n",
    "    print(test)\n",
    "    train_X = [X[i*T:i*T+T] for i in train]    \n",
    "\n",
    "    train_Y = [Y[i] for i in train]\n",
    "    test_Y = [Y[i] for i in test]\n",
    "\n",
    "    #concat all subjects\n",
    "    model=build_model(np.vstack(train_X))\n",
    "\n",
    "    print(\"Computing Correlation\")\n",
    "    train_D = [model.predict(X[i*T:i*T+T]) for i in train]\n",
    "    test_D = [model.predict(X[i*T:i*T+T]) for i in test]\n",
    "\n",
    "    #Release GPU memory after model is used\n",
    "    from keras import backend as K\n",
    "    K.clear_session()\n",
    "\n",
    "    train_FC=corr(train_D)\n",
    "    test_FC=corr(test_D)\n",
    "\n",
    "    score=classify(train_FC,train_Y, test_FC, test_Y)\n",
    "    cvscores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

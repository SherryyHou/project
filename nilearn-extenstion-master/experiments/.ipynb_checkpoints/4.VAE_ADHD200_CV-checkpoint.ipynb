{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "def build_model(x_train):\n",
    "\n",
    "'''This script demonstrates how to build a variational autoencoder with Keras.\n",
    "\n",
    " #Reference\n",
    "\n",
    " - Auto-Encoding Variational Bayes\n",
    "   https://arxiv.org/abs/1312.6114\n",
    "'''\n",
    "\n",
    "\n",
    "    batch_size = 20\n",
    "    original_dim=x_train.shape[1]\n",
    "    latent_dim = 32\n",
    "    intermediate_dim = 500\n",
    "    epochs = 10\n",
    "    epsilon_std = 1.0\n",
    "\n",
    "\n",
    "    x = Input(shape=(original_dim,))\n",
    "    h = Dense(256, activation='tanh')(x)\n",
    "    h = Dense(128, activation='tanh')(h)\n",
    "    h = Dense(64, activation='tanh')(h)\n",
    "    z_mean = Dense(latent_dim)(h)\n",
    "    z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                                  stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "    # we instantiate these layers separately so as to reuse them later\n",
    "\n",
    "    h_decoded = Dense(64, activation='tanh')(z)\n",
    "    h_decoded = Dense(128, activation='tanh')(h_decoded)\n",
    "    h_decoded = Dense(256, activation='tanh')(h_decoded)\n",
    "    x_decoded_mean = Dense(original_dim, activation='sigmoid')(h_decoded)\n",
    "\n",
    "    # instantiate VAE model\n",
    "    vae = Model(x, x_decoded_mean)\n",
    "\n",
    "    # Compute VAE loss\n",
    "    xent_loss = original_dim * metrics.binary_crossentropy(x,x_decoded_mean )\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "    vae.add_loss(vae_loss)\n",
    "    from keras import optimizers\n",
    "    rmsprop=optimizers.RMSprop(lr=0.00001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    vae.compile(optimizer=rmsprop)\n",
    "    vae.summary()\n",
    "\n",
    "\n",
    "    vae.fit(x_train,\n",
    "            shuffle=True,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size)\n",
    "\n",
    "    encoder = Model(x, z_mean)\n",
    "\n",
    "\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decomposition import CanICA\n",
    "def prepare_data(func_filenames):\n",
    "    canica = CanICA(memory=\"nilearn_cache\", memory_level=2,\n",
    "                    threshold=3., verbose=10, random_state=0, \n",
    "                    mask='/home/share/TmpData/Qinglin/ADHD200_Athena_preproc_flirtfix/ADHD200_mask_152_4mm.nii.gz')\n",
    "    data=canica.prepare_data(func_filenames)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "def corr(all_time_series):\n",
    "    connectivity_biomarkers = {}\n",
    "    conn_measure = ConnectivityMeasure(kind='correlation', vectorize=True)\n",
    "    connectivity_biomarkers = conn_measure.fit_transform(all_time_series)\n",
    "    return connectivity_biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "def classify(train_X,train_Y, test_X, test_Y):\n",
    "    names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "             \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "             \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "    classifiers = [\n",
    "        KNeighborsClassifier(3),\n",
    "        SVC(kernel=\"linear\", C=0.025),\n",
    "        SVC(gamma=2, C=1),\n",
    "        GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "        DecisionTreeClassifier(max_depth=5),\n",
    "        RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "        MLPClassifier(alpha=1),\n",
    "        AdaBoostClassifier(),\n",
    "        GaussianNB(),\n",
    "        QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "    scores = []\n",
    "    \n",
    "    for name, clf in zip(names, classifiers):\n",
    "        clf.fit(train_X, train_Y) \n",
    "        score=clf.score(test_X,test_Y)\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def CV(X,Y):\n",
    "    \n",
    "    # define 10-fold cross validation test harness\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    cvscores = []\n",
    "    \n",
    "    # trick. split(Y,Y) instead of split(X,Y) due to X is already concatnated \n",
    "    for train,test in kfold.split(Y,Y):   \n",
    "        #indexing of specific subjects\n",
    "        print(test)\n",
    "        train_X = [X[i*20:i*20+20] for i in train]    \n",
    "\n",
    "        train_Y = [Y[i] for i in train]\n",
    "        test_Y = [Y[i] for i in test]\n",
    "\n",
    "        #concat all subjects\n",
    "        model=build_model(np.vstack(train_X))\n",
    "\n",
    "        print(\"Computing Correlation\")\n",
    "        train_D = [model.predict(X[i*20:i*20+20]) for i in train]\n",
    "        test_D = [model.predict(X[i*20:i*20+20]) for i in test]\n",
    "\n",
    "        #Release GPU memory after model is used\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        \n",
    "        train_FC=corr(train_D)\n",
    "        test_FC=corr(test_D)\n",
    "\n",
    "        score=classify(train_FC,train_Y, test_FC, test_Y)\n",
    "        cvscores.append(score)\n",
    "    return cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/ADHD200_Athena_preproc_flirtfix/NYU/motion/sfnwmrdamotion_session_1_rest_1.nii.gz\n",
      "/home/share/TmpData/Qinglin/ADHD200_Athena_preproc_flirtfix/NYU/NYU_phenotypic.csv/sfnwmrdaNYU_phenotypic.csv_session_1_rest_1.nii.gz\n",
      "216\n"
     ]
    }
   ],
   "source": [
    "X=np.load('/home/share/TmpData/Qinglin/ADHD200_Athena_preproc_flirtfix/NYU/All_Data.npy')\n",
    "Y=np.load('/home/share/TmpData/Qinglin/ADHD200_Athena_preproc_flirtfix/NYU/All_Labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 7 9]\n",
      "(140, 28546)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_split.py:626: Warning: The least populated class in y has only 4 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "140/140 [==============================] - 2s 11ms/step - loss: 5.3563\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 0s 832us/step - loss: 5.4569\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 0s 811us/step - loss: 4.8588\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 0s 827us/step - loss: 4.3982\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 0s 813us/step - loss: 3.9158\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 0s 785us/step - loss: 3.6408\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 0s 826us/step - loss: 3.3780\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 0s 810us/step - loss: 3.1216\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 0s 887us/step - loss: 2.9019\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 0s 908us/step - loss: 2.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:686: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 6]\n",
      "(160, 28546)\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 5.7338\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 0s 871us/step - loss: 5.7484\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 0s 889us/step - loss: 5.1703\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 0s 869us/step - loss: 4.7063\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 0s 922us/step - loss: 4.3869\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 0s 887us/step - loss: 4.0118\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 0s 921us/step - loss: 3.7707\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 0s 903us/step - loss: 3.4597\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 0s 893us/step - loss: 3.3199\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 0s 916us/step - loss: 3.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:686: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5]\n",
      "(160, 28546)\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 5.6681\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 0s 844us/step - loss: 5.6362\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 0s 823us/step - loss: 5.0895\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 0s 825us/step - loss: 4.5873\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 0s 841us/step - loss: 4.1896\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 0s 905us/step - loss: 3.8520\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 0s 901us/step - loss: 3.6120\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 0s 892us/step - loss: 3.4200\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 0s 930us/step - loss: 3.1831\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 0s 896us/step - loss: 2.9654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:686: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3]\n",
      "(160, 28546)\n",
      "Epoch 1/10\n",
      "160/160 [==============================] - 2s 10ms/step - loss: 5.8387\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - 0s 844us/step - loss: 5.8684\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - 0s 846us/step - loss: 5.2460\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - 0s 826us/step - loss: 4.7587\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - 0s 808us/step - loss: 4.3048\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - 0s 825us/step - loss: 4.0281\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - 0s 839us/step - loss: 3.7449\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - 0s 842us/step - loss: 3.5018\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - 0s 914us/step - loss: 3.3495\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - 0s 905us/step - loss: 3.1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:686: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "(180, 28546)\n",
      "Epoch 1/10\n",
      "180/180 [==============================] - 2s 8ms/step - loss: 6.1261\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 0s 818us/step - loss: 6.0851\n",
      "Epoch 3/10\n",
      "180/180 [==============================] - 0s 789us/step - loss: 5.5323\n",
      "Epoch 4/10\n",
      "180/180 [==============================] - 0s 797us/step - loss: 5.0077\n",
      "Epoch 5/10\n",
      "180/180 [==============================] - 0s 837us/step - loss: 4.6372\n",
      "Epoch 6/10\n",
      "180/180 [==============================] - 0s 846us/step - loss: 4.3203\n",
      "Epoch 7/10\n",
      "180/180 [==============================] - 0s 845us/step - loss: 4.0105\n",
      "Epoch 8/10\n",
      "180/180 [==============================] - 0s 854us/step - loss: 3.7905\n",
      "Epoch 9/10\n",
      "180/180 [==============================] - 0s 858us/step - loss: 3.7004\n",
      "Epoch 10/10\n",
      "180/180 [==============================] - 0s 875us/step - loss: 3.4823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:686: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "cvscores=CV(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.3333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.6666666666666666,\n",
       "  0.3333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.3333333333333333,\n",
       "  0.6666666666666666,\n",
       "  0.0,\n",
       "  0.6666666666666666,\n",
       "  0.3333333333333333],\n",
       " [0.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, 0.0],\n",
       " [0.5, 0.5, 0.5, 0.5, 0.0, 1.0, 0.5, 0.0, 0.5, 0.5],\n",
       " [0.5, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
       " [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
